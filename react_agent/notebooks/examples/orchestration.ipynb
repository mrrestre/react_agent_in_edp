{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c3ca2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gen_ai_hub.orchestration.utils import load_text_file \n",
    "\n",
    "# Load the CV file content \n",
    "cv_file_path = \"cv.txt\" # Specify the correct path to the CV file \n",
    "cv_content = load_text_file(cv_file_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23c9595d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gen_ai_hub.orchestration.models.message import SystemMessage, UserMessage \n",
    "from gen_ai_hub.orchestration.models.template import Template, TemplateValue \n",
    "from gen_ai_hub.orchestration.models.response_format import ResponseFormatJsonSchema\n",
    "\n",
    "json_schema = {\n",
    "    \"title\": \"Search Query\",\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "            \"search_query\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"Query that is optimized web search.\"\n",
    "        },\n",
    "            \"justification\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"Why this query is relevant to the user's request.\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Define the template for resume screening \n",
    "template = Template( \n",
    "    messages=[ \n",
    "        SystemMessage(\"\"\"You are a helpful AI assistant with deep knowledge in sciences and web searching\"\"\"), \n",
    "\n",
    "        UserMessage( \n",
    "            \"Here is a questions: {{?question}}\" \n",
    "        ), \n",
    "    ], \n",
    "    defaults=[ \n",
    "        TemplateValue(name=\"question\", value=\"Some intersting science question\"), \n",
    "    ],\n",
    "    response_format = ResponseFormatJsonSchema(name=\"person\", description=\"person mapping\", schema=json_schema),\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef18cb8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model configurations created successfully:\n"
     ]
    }
   ],
   "source": [
    "from gen_ai_hub.orchestration.models.llm import LLM\n",
    "from gen_ai_hub.orchestration.models.config import OrchestrationConfig \n",
    "\n",
    "# List of models to use \n",
    "models = [ \n",
    "    LLM(name=\"gpt-4o\", version=\"latest\", parameters={\"max_tokens\": 1000, \"temperature\": 0.6}), \n",
    "    LLM(name=\"gemini-1.5-pro\", version=\"latest\", parameters={\"max_tokens\": 1000, \"temperature\": 0.6}),\n",
    "] \n",
    "\n",
    "# Create configurations for each model \n",
    "configs = [] \n",
    "for model in models: \n",
    "    # Create orchestration config for each model \n",
    "    config = OrchestrationConfig( \n",
    "        template=template,\n",
    "        llm=model,\n",
    "    ) \n",
    "    configs.append(config) \n",
    "\n",
    "print(\"Model configurations created successfully:\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b3ff58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gen_ai_hub.orchestration.service import OrchestrationService\n",
    "\n",
    "ORCH_URL = \"https://api.ai.intprod-eu12.eu-central-1.aws.ml.hana.ondemand.com/v2/inference/deployments/d809d5b40514e546\"\n",
    "question = \"How does Calcium CT score relate to high cholesterol?\"\n",
    "\n",
    "# Initialize an empty list to store the responses \n",
    "responses = [] \n",
    "\n",
    "# Iterate through each config and get the response using the filtered input \n",
    "for i, config in enumerate(configs): \n",
    "    orchestration_service = OrchestrationService(api_url=ORCH_URL, config=config)\n",
    "    # Run orchestration with the provided input (for example, candidate resume content) \n",
    "    result = orchestration_service.run(template_values=[ \n",
    "        TemplateValue(name=\"question\", value=question)\n",
    "    ])\n",
    "    # Extract the response content \n",
    "    response = result.orchestration_result.choices[0].message.content\n",
    "    # Append the response to the responses list \n",
    "    responses.append({ \n",
    "        \"model\": models[i].name,    # Store model name \n",
    "        \"response\": response        # Store the corresponding model response \n",
    "    }) \n",
    "\n",
    "# Store the responses in a text file \n",
    "with open(\"model_responses.txt\", \"w\") as file: \n",
    "    for response_data in responses: \n",
    "        file.write(f\"Response from model {response_data['model']}:\\n\") \n",
    "        file.write(f\"{response_data['response']}\\n\") \n",
    "        file.write(\"-\" * 80 + \"\\n\") # Add a separator between model responses"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "react-agent-CUxtcVGL-py3.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
