{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/i589287/Library/Caches/pypoetry/virtualenvs/react-agent-CUxtcVGL-py3.13/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "from langchain_mcp_adapters.client import MultiServerMCPClient\n",
    "\n",
    "from react_agent.src.agents.react_agent import ReActAgent\n",
    "from react_agent.src.agents.triage import Triage\n",
    "\n",
    "from react_agent.src.util.tools_fabric import ToolsFabric\n",
    "\n",
    "from experiments.models.experiment_models import LabeledQAPairFacts, ExperimentResult\n",
    "from experiments.fact_score.fact_scorer import FactScorer\n",
    "from experiments.metrics.bert_score import BertScore\n",
    "from experiments.metrics.rouge_score import RougeScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_MCP = False\n",
    "DEBUG_MODE = False\n",
    "\n",
    "fact_scorer = FactScorer()\n",
    "path_to_ressources = \"./resources/02_facts/\"\n",
    "\n",
    "files = {\n",
    "    \"extensibility\": \"extensibility_assistance_facts.json\",\n",
    "    \"malaysia\": \"malaysia_support_facts.json\",\n",
    "    \"peppol\": \"peppol_support_facts.json\",\n",
    "    \"all\": \"all_cases_facts.json\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = os.path.abspath(path_to_ressources + files[\"all\"])\n",
    "\n",
    "\n",
    "with open(file_path, encoding=\"utf8\") as f:\n",
    "    data = json.load(f)\n",
    "    data_set = [LabeledQAPairFacts(**item) for item in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select 3 random elements\n",
    "random_data_set = random.sample(data_set, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Asking agent question with id: PS-3\n",
      "Finished agent execution\n",
      "Started FactScore calculation\n",
      "Started BertScore calculation\n",
      "Started Rouge calculation\n",
      "Finished experiment for id: PS-3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "triage_agent = Triage()\n",
    "execution_trail = \"\"\n",
    "experiment_results: list[ExperimentResult] = []\n",
    "\n",
    "for data_row in random_data_set:\n",
    "    result = ExperimentResult(\n",
    "        id=data_row.id,\n",
    "        question=data_row.question,\n",
    "        answer=data_row.answer,\n",
    "        product=data_row.product,\n",
    "        category=data_row.category,\n",
    "        persona=data_row.persona,\n",
    "        activity=data_row.activity,\n",
    "        country=data_row.country,\n",
    "    )\n",
    "    print(f\"Asking agent question with id: {data_row.id}\")\n",
    "    query_categorization = triage_agent.triage_user_message(\n",
    "        user_message=data_row.question\n",
    "    )\n",
    "    if DEBUG_MODE:\n",
    "        print(f\"Query categorization: {query_categorization}\")\n",
    "\n",
    "    tools = ToolsFabric.get_tools_for_category(\n",
    "        use_mcp=USE_MCP,\n",
    "        configuration=query_categorization[\"category\"],\n",
    "    )\n",
    "\n",
    "    if USE_MCP:\n",
    "        async with MultiServerMCPClient(tools) as client:\n",
    "            agent = ReActAgent(tool_list=client.get_tools())\n",
    "            execution_trail = await agent.arun_agent_with_input(\n",
    "                user_message=query_categorization[\"user_query\"], debug=DEBUG_MODE\n",
    "            )\n",
    "    else:\n",
    "        agent = ReActAgent(tool_list=tools)\n",
    "        execution_trail = agent.run_agent_with_input(\n",
    "            user_message=query_categorization[\"user_query\"], debug=DEBUG_MODE\n",
    "        )\n",
    "\n",
    "    run_data = agent.get_execution_data()\n",
    "\n",
    "    result.tools_used = run_data.tools_used\n",
    "    result.excecution_time_seconds = run_data.excecution_time_seconds\n",
    "    result.model_used = run_data.model_used\n",
    "    result.tokens_consumed = run_data.tokens_consumed\n",
    "    result.llm_call_count = run_data.llm_call_count\n",
    "    result.facts = data_row.facts\n",
    "\n",
    "    print(\"Finished agent execution\")\n",
    "\n",
    "    print(\"Started FactScore calculation\")\n",
    "    result.fact_score = await fact_scorer.get_fact_score(\n",
    "        facts=data_row.facts,\n",
    "        knowledge_source=run_data.final_output,\n",
    "        debug=DEBUG_MODE,\n",
    "    )\n",
    "\n",
    "    print(\"Started BERTScore calculation\")\n",
    "    result.bert_score = BertScore.compute_score(\n",
    "        expected_response=data_row.answer, actual_response=run_data.final_output\n",
    "    )\n",
    "\n",
    "    print(f\"Finished experiment for id: {data_row.id}\\n\")\n",
    "\n",
    "    experiment_results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/i589287/Library/Caches/pypoetry/virtualenvs/react-agent-CUxtcVGL-py3.13/lib/python3.13/site-packages/pydantic/main.py:426: UserWarning: Pydantic serializer warnings:\n",
      "  Expected `float` but got `FactScoreResult` with value `FactScoreResult(direct_fa...rocess specifically.')])` - serialized value may not be as expected\n",
      "  return self.__pydantic_serializer__.to_python(\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "question",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "answer",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "product",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "category",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "persona",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "activity",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "country",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "facts",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "bert_score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "rouge_score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "tools_used",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "excecution_time_seconds",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "model_used",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "llm_call_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "fact_score.direct_fact_score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "fact_score.supporting_fact_score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "fact_score.combined_fact_score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "fact_score.direct_facts",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "fact_score.supporting_facts",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "tokens_consumed.input_tokens",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "tokens_consumed.output_tokens",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "tokens_consumed.total_tokens",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "1aa7d3a3-3077-442b-9520-039423b9583f",
       "rows": [
        [
         "0",
         "PS-3",
         "Incoming ZUGFeRD invoices (from suppliers) we load in the eDocument Cockpit using the PUSH SOAP Service DCPPUSHSERVICE . We have an own development to extract the XML attached in the PDF A/3 and load this in the eCockpit. That works very good. The question is what we do with the PDF itself. According to the service documentation of SOAP service DCPPUSHSERVICE we can add HTML version of the XML or PDF as attachments. We tried boths and both is working. But in eDocument Cockpit we  have for incoming edocuments only a buttoon to display HTML. How can we display the PDF that originally represents the ZUGFeRD invoice?",
         "Here are some hints that might be helpful. We haven't tried out those yet, but it may be worth to give it a try.\nextend EDOPROCFUNCASGV as indicated in Configure the eDocument Cockpit | SAP Help Portal \nextend EDOPROCFUNCARCV as indicated in Configure the eDocument Cockpit | SAP Help Portal \nalternatively, consider to override the HTML Display Function using some custom logic, e.g. show a follow-up Popup that let's the user decide whether the HTML or PDF shall be displayed or not - EDOACTIONUIPROCV as indicated in Configure the eDocument Cockpit | SAP Help Portal \nYou'll find some screenshots, including the Display PDF Action implementation for the Outgoing E-Mail Process",
         null,
         null,
         null,
         null,
         null,
         "[{'fact': 'Extend EDOPROCFUNCASGV as indicated in Configure the eDocument Cockpit.', 'classification': 'direct', 'id': 'PS-3-1'}, {'fact': 'Extend EDOPROCFUNCARCV as indicated in Configure the eDocument Cockpit.', 'classification': 'direct', 'id': 'PS-3-2'}, {'fact': 'Consider overriding the HTML Display Function using custom logic.', 'classification': 'direct', 'id': 'PS-3-3'}, {'fact': 'Custom logic could include showing a follow-up popup for user choice between HTML or PDF display.', 'classification': 'direct', 'id': 'PS-3-4'}, {'fact': 'EDOACTIONUIPROCV is indicated in Configure the eDocument Cockpit.', 'classification': 'supporting', 'id': 'PS-3-5'}, {'fact': 'Screenshots include the Display PDF Action implementation for the Outgoing E-Mail Process.', 'classification': 'supporting', 'id': 'PS-3-6'}]",
         "0.07669785618782043",
         "0.2767857142857143",
         "[{'tool_name': 'abap_method_codebase_search', 'arguments': {'query': 'DCPPUSHSERVICE PDF display'}}, {'tool_name': 'abap_method_codebase_search', 'arguments': {'query': 'EFG_DISPLAY_PDF'}}]",
         "14.577",
         "gpt-4o",
         "10",
         "0.0",
         "0.0",
         "0.0",
         "[{'fact': 'Extend EDOPROCFUNCASGV as indicated in Configure the eDocument Cockpit.', 'is_contained': False, 'reason': 'The context does not mention extending EDOPROCFUNCASGV or any specific configuration instructions related to it.'}, {'fact': 'Extend EDOPROCFUNCARCV as indicated in Configure the eDocument Cockpit.', 'is_contained': False, 'reason': 'The context does not mention extending EDOPROCFUNCARCV or any specific configuration instructions related to it.'}, {'fact': 'Consider overriding the HTML Display Function using custom logic.', 'is_contained': False, 'reason': 'The context discusses methods for displaying PDFs using the EFG_DISPLAY_PDF function but does not mention overriding the HTML Display Function or using custom logic for HTML display.'}, {'fact': 'Custom logic could include showing a follow-up popup for user choice between HTML or PDF display.', 'is_contained': False, 'reason': 'The context discusses methods for displaying PDF content but does not mention custom logic for a popup offering a choice between HTML or PDF display.'}]",
         "[{'fact': 'EDOACTIONUIPROCV is indicated in Configure the eDocument Cockpit.', 'is_contained': False, 'reason': 'The context does not mention EDOACTIONUIPROCV or its indication in the eDocument Cockpit configuration.'}, {'fact': 'Screenshots include the Display PDF Action implementation for the Outgoing E-Mail Process.', 'is_contained': False, 'reason': 'The context discusses the implementation of PDF display functionality using the EFG_DISPLAY_PDF function within certain methods, but does not mention screenshots or the Outgoing E-Mail Process specifically.'}]",
         "11688",
         "641",
         "12329"
        ]
       ],
       "shape": {
        "columns": 23,
        "rows": 1
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>product</th>\n",
       "      <th>category</th>\n",
       "      <th>persona</th>\n",
       "      <th>activity</th>\n",
       "      <th>country</th>\n",
       "      <th>facts</th>\n",
       "      <th>bert_score</th>\n",
       "      <th>...</th>\n",
       "      <th>model_used</th>\n",
       "      <th>llm_call_count</th>\n",
       "      <th>fact_score.direct_fact_score</th>\n",
       "      <th>fact_score.supporting_fact_score</th>\n",
       "      <th>fact_score.combined_fact_score</th>\n",
       "      <th>fact_score.direct_facts</th>\n",
       "      <th>fact_score.supporting_facts</th>\n",
       "      <th>tokens_consumed.input_tokens</th>\n",
       "      <th>tokens_consumed.output_tokens</th>\n",
       "      <th>tokens_consumed.total_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PS-3</td>\n",
       "      <td>Incoming ZUGFeRD invoices (from suppliers) we ...</td>\n",
       "      <td>Here are some hints that might be helpful. We ...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[{'fact': 'Extend EDOPROCFUNCASGV as indicated...</td>\n",
       "      <td>0.076698</td>\n",
       "      <td>...</td>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[{'fact': 'Extend EDOPROCFUNCASGV as indicated...</td>\n",
       "      <td>[{'fact': 'EDOACTIONUIPROCV is indicated in Co...</td>\n",
       "      <td>11688</td>\n",
       "      <td>641</td>\n",
       "      <td>12329</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                                           question  \\\n",
       "0  PS-3  Incoming ZUGFeRD invoices (from suppliers) we ...   \n",
       "\n",
       "                                              answer product category persona  \\\n",
       "0  Here are some hints that might be helpful. We ...    None     None    None   \n",
       "\n",
       "  activity country                                              facts  \\\n",
       "0     None    None  [{'fact': 'Extend EDOPROCFUNCASGV as indicated...   \n",
       "\n",
       "   bert_score  ...  model_used llm_call_count  fact_score.direct_fact_score  \\\n",
       "0    0.076698  ...      gpt-4o             10                           0.0   \n",
       "\n",
       "  fact_score.supporting_fact_score  fact_score.combined_fact_score  \\\n",
       "0                              0.0                             0.0   \n",
       "\n",
       "                             fact_score.direct_facts  \\\n",
       "0  [{'fact': 'Extend EDOPROCFUNCASGV as indicated...   \n",
       "\n",
       "                         fact_score.supporting_facts  \\\n",
       "0  [{'fact': 'EDOACTIONUIPROCV is indicated in Co...   \n",
       "\n",
       "   tokens_consumed.input_tokens tokens_consumed.output_tokens  \\\n",
       "0                         11688                           641   \n",
       "\n",
       "  tokens_consumed.total_tokens  \n",
       "0                        12329  \n",
       "\n",
       "[1 rows x 23 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records = [r.model_dump(mode=\"json\") for r in experiment_results]\n",
    "df = pd.json_normalize(records)\n",
    "\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "react-agent-CUxtcVGL-py3.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
