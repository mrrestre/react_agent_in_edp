{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04706785",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "from experiments.interpretation.interpretation_util import (\n",
    "    ExperimentFiles,\n",
    "    ExperimentFolders,\n",
    ")\n",
    "\n",
    "\n",
    "notebook_dir = os.path.abspath(\"\")\n",
    "\n",
    "file_path = os.path.abspath(\n",
    "    os.path.join(\n",
    "        notebook_dir,\n",
    "        \"..\",\n",
    "        \"results\",\n",
    "        \"experiments\",\n",
    "        ExperimentFolders.O3,\n",
    "        ExperimentFiles.ALL_TOOLS_LOCAL,\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "# Load JSON data (as list of dicts)\n",
    "with open(file_path) as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5c888d",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b79c3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to count contained and total facts\n",
    "def count_facts(fact_list):\n",
    "    if not isinstance(fact_list, list):\n",
    "        return 0, 0\n",
    "    total = len(fact_list)\n",
    "    contained = sum(f.get(\"is_contained\", False) for f in fact_list)\n",
    "    return contained, total\n",
    "\n",
    "\n",
    "# Apply to dataframe\n",
    "df[\"direct_facts_contained\"], df[\"direct_facts_total\"] = zip(\n",
    "    *df[\"fact_score.direct_facts\"].apply(count_facts)\n",
    ")\n",
    "df[\"supporting_facts_contained\"], df[\"supporting_facts_total\"] = zip(\n",
    "    *df[\"fact_score.supporting_facts\"].apply(count_facts)\n",
    ")\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Define conditions based on the 'id' prefix\n",
    "conditions = [\n",
    "    df[\"id\"].str.startswith(\"EA\"),\n",
    "    df[\"id\"].str.startswith(\"MS\"),\n",
    "    df[\"id\"].str.startswith(\"PS\"),\n",
    "    df[\"id\"].str.startswith(\"STC\"),\n",
    "]\n",
    "\n",
    "# Corresponding labels\n",
    "labels = [\n",
    "    \"Extensibility Assistance\",\n",
    "    \"Malaysia Support\",\n",
    "    \"Peppol Support\",\n",
    "    \"Settlement Cases\",\n",
    "]\n",
    "\n",
    "# Create the new column\n",
    "df[\"case_type\"] = np.select(conditions, labels, default=\"Unknown\")\n",
    "\n",
    "df = df.sort_values(by=\"id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b19be40",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e897e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b54f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4cdacbe",
   "metadata": {},
   "source": [
    "# Distribution of Direct Fact Scores by Case Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1b799a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Add \"All Cases\" rows\n",
    "df_all = df.copy()\n",
    "df_all[\"case_type\"] = \"All Cases\"\n",
    "df_combined = pd.concat([df, df_all], ignore_index=True)\n",
    "\n",
    "# Define custom order (All Cases first)\n",
    "case_order = [\n",
    "    \"All Cases\",\n",
    "    \"Extensibility Assistance\",\n",
    "    \"Malaysia Support\",\n",
    "    \"Peppol Support\",\n",
    "    \"Settlement Cases\",\n",
    "]\n",
    "\n",
    "# Custom palette including All Cases\n",
    "custom_palette = {\n",
    "    \"Extensibility Assistance\": \"#66c2a5\",\n",
    "    \"Malaysia Support\": \"#fc8d62\",\n",
    "    \"Peppol Support\": \"#8da0cb\",\n",
    "    \"Settlement Cases\": \"#e78ac3\",\n",
    "    \"All Cases\": \"#999999\",\n",
    "}\n",
    "\n",
    "plt.figure(figsize=(11, 6))\n",
    "\n",
    "# Boxplot with specified order\n",
    "ax = sns.boxplot(\n",
    "    data=df_combined,\n",
    "    x=\"case_type\",\n",
    "    y=\"fact_score.direct_fact_score\",\n",
    "    order=case_order,\n",
    "    palette=custom_palette,\n",
    "    linewidth=1.5,\n",
    "    showfliers=False,\n",
    "    whis=[0, 100],\n",
    ")\n",
    "\n",
    "# Compute mean and median\n",
    "grouped = df_combined.groupby(\"case_type\")[\"fact_score.direct_fact_score\"]\n",
    "medians = grouped.median()\n",
    "means = grouped.mean()\n",
    "\n",
    "# Add lines and labels\n",
    "for x, case_type in enumerate(case_order):\n",
    "    median = medians[case_type]\n",
    "    mean = means[case_type]\n",
    "\n",
    "    # Mean (red dashed)\n",
    "    ax.hlines(\n",
    "        mean,\n",
    "        x - 0.4,\n",
    "        x + 0.4,\n",
    "        colors=\"red\",\n",
    "        linestyles=\"--\",\n",
    "        linewidth=2,\n",
    "        label=\"Mean\" if x == 0 else \"\",\n",
    "    )\n",
    "\n",
    "    # Labels\n",
    "    ax.text(\n",
    "        x + 0.2, median + 0.02, f\"{median:.2f}\", color=\"black\", va=\"center\", fontsize=10\n",
    "    )\n",
    "    ax.text(x - 0.3, mean + 0.02, f\"{mean:.2f}\", color=\"red\", va=\"center\", fontsize=10)\n",
    "\n",
    "# Plot settings\n",
    "plt.title(\n",
    "    \"Distribution of Direct Fact Scores by Case Type (with All Cases First)\",\n",
    "    fontsize=14,\n",
    ")\n",
    "plt.xlabel(\"Case Type\")\n",
    "plt.ylabel(\"Direct Fact Score\")\n",
    "plt.ylim(0, 1)\n",
    "plt.xticks(rotation=30)\n",
    "plt.grid(True, axis=\"y\", linestyle=\"--\", alpha=0.6)\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147d0a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize counter\n",
    "tool_counts = Counter()\n",
    "\n",
    "# Loop through each list of tools\n",
    "for tools_list in df[\"tools_used\"]:\n",
    "    if isinstance(tools_list, list):\n",
    "        for tool in tools_list:\n",
    "            tool_name = tool.get(\"tool_name\")\n",
    "            if tool_name:\n",
    "                tool_counts[tool_name] += 1\n",
    "\n",
    "# Convert to DataFrame\n",
    "tool_df = pd.DataFrame(tool_counts.items(), columns=[\"Tool Name\", \"Usage Count\"])\n",
    "tool_df = tool_df.sort_values(by=\"Usage Count\", ascending=False)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(tool_df[\"Tool Name\"], tool_df[\"Usage Count\"], color=\"mediumseagreen\")\n",
    "plt.title(\"Distribution of Tool Usage Across Experiments\")\n",
    "plt.xlabel(\"Tool Name\")\n",
    "plt.ylabel(\"Usage Count\")\n",
    "plt.xticks(rotation=30)\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ff6fec",
   "metadata": {},
   "source": [
    "# Stacked Distribution of Agent Outcomes by Case Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88f78ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# First, prepare the data\n",
    "# Ensure 'case_type' exists and 'agent_judge_outcome' is consistent\n",
    "df_casewise = (\n",
    "    df.groupby([\"case_type\", \"agent_judge_outcome\"]).size().unstack(fill_value=0)\n",
    ")\n",
    "\n",
    "# Add \"All Cases\"\n",
    "df_all = df[\"agent_judge_outcome\"].value_counts().to_frame().T\n",
    "df_all.index = [\"All Cases\"]\n",
    "\n",
    "# Combine\n",
    "df_combined = pd.concat([df_all, df_casewise])\n",
    "\n",
    "# Plot\n",
    "ax = df_combined.plot(\n",
    "    kind=\"bar\", stacked=True, figsize=(12, 6), colormap=\"Set2\", edgecolor=\"black\"\n",
    ")\n",
    "\n",
    "# Customize\n",
    "plt.title(\"Stacked Distribution of Agent Outcomes by Case Type\")\n",
    "plt.xlabel(\"Case Type\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.xticks(rotation=30, ha=\"right\")\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.6)\n",
    "plt.legend(title=\"Agent Judge Outcome\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c403ec",
   "metadata": {},
   "source": [
    "# Distribution of LLM Judge Outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01479fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"agent_judge_outcome\"].value_counts().plot(kind=\"bar\")\n",
    "plt.title(\"Distribution of LLM Judge Outcomes\")\n",
    "plt.xlabel(\"Outcome\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.grid(axis=\"y\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544d6b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.countplot(data=df, x=\"agent_judge_outcome\", hue=\"case_type\")\n",
    "plt.title(\"Distribution of LLM Judge Outcomes by Case Type\")\n",
    "plt.xlabel(\"Outcome\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.grid(axis=\"y\")\n",
    "plt.legend(title=\"Case Type\", bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceec43c3",
   "metadata": {},
   "source": [
    "# BERT Score per Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f156c7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define colors for each case_type\n",
    "case_colors = {\n",
    "    \"Extensibility Assistance\": \"skyblue\",\n",
    "    \"Malaysia Support\": \"orange\",\n",
    "    \"Peppol Support\": \"green\",\n",
    "    \"Settlement Cases\": \"red\",\n",
    "}\n",
    "\n",
    "# Map colors to case_type\n",
    "colors = df[\"case_type\"].map(case_colors)\n",
    "\n",
    "plt.figure(figsize=(14, 5))\n",
    "plt.bar(df[\"id\"], df[\"bert_score\"], color=colors)\n",
    "plt.xlabel(\"Experiment ID\")\n",
    "plt.ylabel(\"BERT Score\")\n",
    "plt.title(\"BERT Score per Experiment (Colored by Case Type)\")\n",
    "plt.ylim(-1, 1)\n",
    "plt.xticks(rotation=90)\n",
    "plt.grid(axis=\"y\")\n",
    "plt.tight_layout()\n",
    "\n",
    "# Create custom legend\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "legend_handles = [\n",
    "    Patch(color=color, label=label) for label, color in case_colors.items()\n",
    "]\n",
    "plt.legend(\n",
    "    handles=legend_handles,\n",
    "    title=\"Case Type\",\n",
    "    bbox_to_anchor=(1.05, 1),\n",
    "    loc=\"upper left\",\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c32bd7c",
   "metadata": {},
   "source": [
    "# Fact Contained per Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c23c6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "x = np.arange(len(df))\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Plot total and contained\n",
    "plt.plot(\n",
    "    x,\n",
    "    df[\"direct_facts_total\"],\n",
    "    label=\"Direct Facts (Total)\",\n",
    "    color=\"orange\",\n",
    "    linewidth=2,\n",
    ")\n",
    "plt.plot(\n",
    "    x,\n",
    "    df[\"direct_facts_contained\"],\n",
    "    label=\"Direct Facts (Contained)\",\n",
    "    color=\"darkgreen\",\n",
    "    linestyle=\"--\",\n",
    "    linewidth=2,\n",
    ")\n",
    "\n",
    "# Fill area between lines\n",
    "plt.fill_between(\n",
    "    x,\n",
    "    df[\"direct_facts_total\"],\n",
    "    df[\"direct_facts_contained\"],\n",
    "    where=(df[\"direct_facts_total\"] > df[\"direct_facts_contained\"]),\n",
    "    interpolate=True,\n",
    "    color=\"lightblue\",\n",
    "    alpha=0.3,\n",
    "    label=\"Missed Direct Facts\",\n",
    ")\n",
    "\n",
    "plt.xticks(x, df[\"id\"], rotation=90)\n",
    "plt.title(\"Direct Facts: Total vs Contained per Experiment\")\n",
    "plt.xlabel(\"Experiment ID\")\n",
    "plt.ylabel(\"Fact Count\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f4884a",
   "metadata": {},
   "source": [
    "# Time consumed for run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7355013",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(\n",
    "    df[\"id\"], df[\"excecution_time_seconds\"], marker=\"o\", linestyle=\"-\", color=\"teal\"\n",
    ")\n",
    "\n",
    "plt.title(\"Execution Time per Run\")\n",
    "plt.xlabel(\"Experiment ID\")\n",
    "plt.ylabel(\"Execution Time (seconds)\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334aeab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "\n",
    "# Plot input, output, and total tokens\n",
    "plt.plot(\n",
    "    df[\"id\"],\n",
    "    df[\"tokens_consumed.input_tokens\"],\n",
    "    label=\"Input Tokens\",\n",
    "    marker=\"o\",\n",
    ")\n",
    "plt.plot(\n",
    "    df[\"id\"],\n",
    "    df[\"tokens_consumed.output_tokens\"],\n",
    "    label=\"Output Tokens\",\n",
    "    marker=\"s\",\n",
    ")\n",
    "\n",
    "plt.title(\"Token Consumption per Run (Excluding Agent Judge)\")\n",
    "plt.xlabel(\"Experiment ID\")\n",
    "plt.ylabel(\"Token Count\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97fd367",
   "metadata": {},
   "source": [
    "# Average Direct Fact Score by LLM Judge Outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8822d80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = (\n",
    "    df.groupby(\"agent_judge_outcome\")[\"fact_score.direct_fact_score\"]\n",
    "    .mean()\n",
    "    .sort_values(ascending=False)\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "grouped.plot(kind=\"bar\", color=\"cornflowerblue\")\n",
    "plt.ylabel(\"Average Direct Fact Score\")\n",
    "plt.title(\"Average Direct Fact Score by LLM Judge Outcome\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis=\"y\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19c2490",
   "metadata": {},
   "source": [
    "# Average Token Consumption by Component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b53208f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Calculate average tokens\n",
    "avg_input = df[\n",
    "    [\"agent_judge_tokens_consumed.input_tokens\", \"tokens_consumed.input_tokens\"]\n",
    "].mean()\n",
    "avg_output = df[\n",
    "    [\"agent_judge_tokens_consumed.output_tokens\", \"tokens_consumed.output_tokens\"]\n",
    "].mean()\n",
    "avg_total = df[\n",
    "    [\"agent_judge_tokens_consumed.total_tokens\", \"tokens_consumed.total_tokens\"]\n",
    "].mean()\n",
    "\n",
    "# Combine into a single DataFrame-like structure\n",
    "avg_tokens_df = {\n",
    "    \"Agent Judge\": [avg_input[0], avg_output[0], avg_total[0]],\n",
    "    \"Agent\": [avg_input[1], avg_output[1], avg_total[1]],\n",
    "}\n",
    "\n",
    "labels = [\"Input Tokens\", \"Output Tokens\", \"Total Tokens\"]\n",
    "x = np.arange(len(labels))\n",
    "bar_width = 0.35\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Bar plots\n",
    "bars_judge = plt.bar(\n",
    "    x - bar_width / 2,\n",
    "    avg_tokens_df[\"Agent Judge\"],\n",
    "    width=bar_width,\n",
    "    label=\"Agent Judge\",\n",
    "    color=\"salmon\",\n",
    ")\n",
    "bars_agent = plt.bar(\n",
    "    x + bar_width / 2,\n",
    "    avg_tokens_df[\"Agent\"],\n",
    "    width=bar_width,\n",
    "    label=\"Agent\",\n",
    "    color=\"cornflowerblue\",\n",
    ")\n",
    "\n",
    "# Add value labels to the tallest bar of each pair\n",
    "for bars in [bars_judge, bars_agent]:\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        plt.text(\n",
    "            bar.get_x() + bar.get_width() / 2,\n",
    "            height + 20,  # vertical offset\n",
    "            f\"{int(height)}\",\n",
    "            ha=\"center\",\n",
    "            va=\"bottom\",\n",
    "            fontsize=10,\n",
    "            fontweight=\"bold\",\n",
    "        )\n",
    "\n",
    "# Aesthetics\n",
    "plt.xticks(x, labels)\n",
    "plt.ylabel(\"Average Token Count\")\n",
    "plt.title(\"Average Token Consumption by Component\")\n",
    "plt.legend()\n",
    "plt.grid(axis=\"y\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1e5eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "import numpy as np\n",
    "\n",
    "from experiments.interpretation.interpretation_util import ModelPricing\n",
    "\n",
    "# Calculate average tokens (already done)\n",
    "avg_input = df[\n",
    "    [\"agent_judge_tokens_consumed.input_tokens\", \"tokens_consumed.input_tokens\"]\n",
    "].mean()\n",
    "avg_output = df[\n",
    "    [\"agent_judge_tokens_consumed.output_tokens\", \"tokens_consumed.output_tokens\"]\n",
    "].mean()\n",
    "\n",
    "# Get model names from the first row\n",
    "judge_model = df.loc[0, \"agent_judge_model\"]\n",
    "agent_model = df.loc[0, \"model_used\"]\n",
    "print(type(ModelPricing))\n",
    "print(ModelPricing)\n",
    "# Compute costs using dictionary keys\n",
    "costs = {\n",
    "    \"Agent Judge\": (avg_input[0] / 1000) * ModelPricing[judge_model][\"input\"]\n",
    "    + (avg_output[0] / 1000) * ModelPricing[judge_model][\"output\"],\n",
    "    \"Agent\": (avg_input[1] / 1000) * ModelPricing[agent_model][\"input\"]\n",
    "    + (avg_output[1] / 1000) * ModelPricing[agent_model][\"output\"],\n",
    "}\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(6, 4))\n",
    "bars = plt.bar(costs.keys(), costs.values(), color=[\"salmon\", \"cornflowerblue\"])\n",
    "\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(\n",
    "        bar.get_x() + bar.get_width() / 2,\n",
    "        height + 0.00005,\n",
    "        f\"${height:.6f}\",\n",
    "        ha=\"center\",\n",
    "        va=\"bottom\",\n",
    "        fontweight=\"bold\",\n",
    "    )\n",
    "\n",
    "plt.ylabel(\"Average Cost ($)\")\n",
    "plt.title(\"Estimated Mean Cost per Experiment\")\n",
    "plt.gca().yaxis.set_major_formatter(mtick.StrMethodFormatter(\"${x:,.6f}\"))\n",
    "plt.grid(axis=\"y\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "react-agent-CUxtcVGL-py3.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
